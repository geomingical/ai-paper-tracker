# ML Paper Journey ğŸ“š

A personal learning tracker for essential Machine Learning and AI papers. Track your reading progress through foundational papers in deep learning, from AlexNet to GPT-4.

![Preview](preview.png)

## Features

- ğŸ¨ **Bento Grid Layout** - Modern Apple-style card design
- ğŸŒ™ **Read/Unread States** - Unread papers appear grayscale, read papers glow
- ğŸ·ï¸ **Category Filtering** - Filter by Foundations, Language Models, Multimodal, Efficiency, or Data
- ğŸ“ **Reading Notes** - Track your thoughts with markdown files
- ğŸ“Š **Progress Tracking** - Visual progress ring shows completion percentage
- ğŸ“± **Responsive** - Works on desktop, tablet, and mobile

## Quick Start

### 1. Deploy to GitHub Pages

1. Fork this repository
2. Go to Settings â†’ Pages
3. Set source to "Deploy from a branch"
4. Select `main` branch and `/docs` folder
5. Your site will be live at `https://yourusername.github.io/repo-name/`

### 2. Track Your Reading

Papers start as **unread** (grayscale cards). To mark a paper as **read**:

1. Create a markdown file in `docs/notes/` with the paper's ID
2. Add your reading notes
3. The card will automatically light up!

**Example**: To mark "Attention Is All You Need" as read:

```bash
# Create the notes file
touch docs/notes/transformer-2017.md
```

Then add your notes:

```markdown
# Attention Is All You Need - Notes

## Key Takeaways
- Self-attention replaces recurrence
- Multi-head attention allows parallel processing
- Positional encoding preserves sequence order

## Questions
- How does the attention mechanism scale?
```

### 3. Paper IDs Reference

| Category | Paper | ID |
|----------|-------|-----|
| ğŸ›ï¸ Foundations | Brook for GPUs | `brook-gpu-2004` |
| ğŸ›ï¸ Foundations | AlexNet | `alexnet-2012` |
| ğŸ›ï¸ Foundations | GAN | `gan-2014` |
| ğŸ›ï¸ Foundations | ResNet | `resnet-2015` |
| ğŸ›ï¸ Foundations | Transformer | `transformer-2017` |
| ğŸ’¬ Language Models | Word2Vec | `word2vec-2013` |
| ğŸ’¬ Language Models | Seq2Seq | `seq2seq-2014` |
| ğŸ’¬ Language Models | Bahdanau Attention | `bahdanau-attention-2015` |
| ğŸ’¬ Language Models | GNMT | `gnmt-2016` |
| ğŸ’¬ Language Models | GPT-1 | `gpt1-2018` |
| ğŸ’¬ Language Models | BERT | `bert-2018` |
| ğŸ’¬ Language Models | GPT-2 | `gpt2-2019` |
| ğŸ’¬ Language Models | GPT-3 | `gpt3-2020` |
| ğŸ’¬ Language Models | InstructGPT | `instructgpt-2022` |
| ğŸ’¬ Language Models | TÃ¼lu 3 | `tulu3-2024` |
| ğŸ¨ Multimodal | Two-Stream CNN | `two-stream-2014` |
| ğŸ¨ Multimodal | Video CNN | `video-cnn-2014` |
| ğŸ¨ Multimodal | Diffusion (Thermodynamics) | `diffusion-thermo-2015` |
| ğŸ¨ Multimodal | AlphaGo Zero | `alphago-zero-2017` |
| ğŸ¨ Multimodal | DDPM | `ddpm-2020` |
| ğŸ¨ Multimodal | ViT | `vit-2020` |
| ğŸ¨ Multimodal | CLIP | `clip-2021` |
| ğŸ¨ Multimodal | Latent Diffusion | `latent-diffusion-2021` |
| ğŸ¨ Multimodal | Chain-of-Thought | `cot-2022` |
| ğŸ¨ Multimodal | DiT | `dit-2022` |
| âš¡ Efficiency | Knowledge Distillation | `distillation-2015` |
| âš¡ Efficiency | MoE | `moe-2017` |
| âš¡ Efficiency | ZeRO | `zero-2019` |
| âš¡ Efficiency | Scaling Laws | `scaling-laws-2020` |
| âš¡ Efficiency | LoRA | `lora-2021` |
| âš¡ Efficiency | Chinchilla | `chinchilla-2022` |
| âš¡ Efficiency | ReAct | `react-2022` |
| ğŸ“Š Data & Scaling | The Bitter Lesson | `bitter-lesson-2019` |
| ğŸ“Š Data & Scaling | LAION-5B | `laion5b-2022` |
| ğŸ“Š Data & Scaling | RefinedWeb | `refinedweb-2023` |
| ğŸ“Š Data & Scaling | MegaScale | `megascale-2024` |

> ğŸ“– **Paper list source**: [Awesome-AITools](https://github.com/ikaijua/Awesome-AITools) â€¢ ç¾åœ˜å…‰å¹´ä¹‹å¤–ç”¢å“è² è²¬äºº è¬é’æ± ï¼šã€ŠAIæ¼”ç¾©ï¼Œ36ç¯‡è«–æ–‡é–‹å•Ÿä½ çš„æ¢ç´¢ä¹‹æ—…ã€‹

## Project Structure

```
ML_AI/
â”œâ”€â”€ .gitignore              # Git ignore rules
â””â”€â”€ docs/                   # GitHub Pages root
    â”œâ”€â”€ index.html          # Main page
    â”œâ”€â”€ styles.css          # Styling
    â”œâ”€â”€ app.js              # JavaScript logic
    â”œâ”€â”€ papers.json         # Paper metadata
    â”œâ”€â”€ preview.png         # Preview image
    â”œâ”€â”€ README.md           # This file
    â””â”€â”€ notes/              # Your reading notes
```

## Customization

### Adding New Papers

Edit `docs/papers.json`:

```json
{
  "id": "my-paper-2024",
  "title": "My Paper Title",
  "authors": ["Author 1", "Author 2"],
  "year": 2024,
  "category": "language-models",
  "filename": "paper.pdf",
  "arxiv": "2401.12345",
  "significance": "Brief description of importance",
  "tags": ["Tag1", "Tag2"]
}
```

### Categories

- `foundations` - ğŸ›ï¸ Core architectures (CNN, Transformer, GAN)
- `language-models` - ğŸ’¬ NLP & LLMs (GPT, BERT, Word2Vec)
- `multimodal` - ğŸ¨ Vision-Language (CLIP, Diffusion, ViT)
- `efficiency` - âš¡ Optimization (LoRA, MoE, Scaling Laws)
- `data` - ğŸ“Š Datasets & Infrastructure (LAION, Scaling)

## Tech Stack

- Pure HTML/CSS/JS (no build step required)
- GitHub Pages compatible
- Markdown support via marked.js (optional)

## License

MIT - Use freely for your personal learning journey!

---

Happy reading! ğŸš€
